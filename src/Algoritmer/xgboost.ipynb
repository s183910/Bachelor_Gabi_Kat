{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages and libraries\r\n",
    "import pandas as pd\r\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost data prep\r\n",
    "#remove white space in columns\r\n",
    "#NOTE: GENDER_bin=1 is female and GENDER_bin=0 is males\r\n",
    "\r\n",
    "df = pd.read_csv(\"df_sum_score_py.csv\")\r\n",
    "df.replace(' ','_',regex=True,inplace=True)\r\n",
    "\r\n",
    "# there were 14 missing values, which has earlier been set to 0 in STRATUM. \r\n",
    "# Since this is only approximately 0.116% of the entire data, we do not need to do anything further. \r\n",
    "# XGBoost is very well at handling missing data, and we just need to ensure that it's set to 0. \r\n",
    "df.STRATUM.isin(['0']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data \r\n",
    "# X is the data which will be used to make predictions, and y contains the data we want to predict.\r\n",
    "# We want to predict the score of the students in college, hence y_training and y_test is the college average grade. \r\n",
    "\r\n",
    "X = df.drop(['COL_GRADE_AVG','GENDER','Unnamed: 0','CR_S11','CC_S11','ENG_S11','CR_PRO','CC_PRO','ENG_PRO'], axis=1).copy()\r\n",
    "y=df['COL_GRADE_AVG'].copy()\r\n",
    "\r\n",
    "# Now we will continue to formatting X to make it suitable for making a model with XGBoost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding \r\n",
    "\r\n",
    "# Look at the different types of data contained in each variable. \r\n",
    "X.dtypes\r\n",
    "\r\n",
    "# The object columns we need to inspect to ensure that they are what we need them to be and after that we will do one-hot encoding. \r\n",
    "# One hot encoding is used to make the categorical varoiable STRATUM work in the model. \r\n",
    "# What is gonna happen is that the categorical variable is becoming multiple columns of binary values. \r\n",
    "# One hot encoding works great for trees and this is the motivation for using this method. \r\n",
    "X_encoded = pd.get_dummies(X,columns=['STRATUM'])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded,y,random_state=24, test_size=0.33)#, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HI_GRADE_AVG</th>\n",
       "      <th>GENDER_bin</th>\n",
       "      <th>STRATUM_0</th>\n",
       "      <th>STRATUM_Stratum_1</th>\n",
       "      <th>STRATUM_Stratum_2</th>\n",
       "      <th>STRATUM_Stratum_3</th>\n",
       "      <th>STRATUM_Stratum_4</th>\n",
       "      <th>STRATUM_Stratum_5</th>\n",
       "      <th>STRATUM_Stratum_6</th>\n",
       "      <th>COL_GRADE_AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>49.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>59.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>59.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>85.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>43.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>43.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10385</th>\n",
       "      <td>67.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>59.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>54.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8315 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HI_GRADE_AVG  GENDER_bin  STRATUM_0  STRATUM_Stratum_1  \\\n",
       "2988      49.333333           0          0                  1   \n",
       "5916      59.666667           1          0                  0   \n",
       "3435      59.333333           0          0                  0   \n",
       "6269      85.666667           0          0                  1   \n",
       "3964      43.666667           1          0                  0   \n",
       "...             ...         ...        ...                ...   \n",
       "5249      43.666667           0          0                  1   \n",
       "10385     67.666667           0          0                  0   \n",
       "3473      59.666667           0          0                  1   \n",
       "8535      54.333333           0          0                  1   \n",
       "899       53.000000           0          0                  0   \n",
       "\n",
       "       STRATUM_Stratum_2  STRATUM_Stratum_3  STRATUM_Stratum_4  \\\n",
       "2988                   0                  0                  0   \n",
       "5916                   0                  1                  0   \n",
       "3435                   1                  0                  0   \n",
       "6269                   0                  0                  0   \n",
       "3964                   1                  0                  0   \n",
       "...                  ...                ...                ...   \n",
       "5249                   0                  0                  0   \n",
       "10385                  0                  0                  1   \n",
       "3473                   0                  0                  0   \n",
       "8535                   0                  0                  0   \n",
       "899                    1                  0                  0   \n",
       "\n",
       "       STRATUM_Stratum_5  STRATUM_Stratum_6  COL_GRADE_AVG  \n",
       "2988                   0                  0      21.000000  \n",
       "5916                   0                  0      64.000000  \n",
       "3435                   0                  0      24.000000  \n",
       "6269                   0                  0      98.333333  \n",
       "3964                   0                  0      10.000000  \n",
       "...                  ...                ...            ...  \n",
       "5249                   0                  0       9.333333  \n",
       "10385                  0                  0      94.000000  \n",
       "3473                   0                  0      69.333333  \n",
       "8535                   0                  0      76.000000  \n",
       "899                    0                  0      59.333333  \n",
       "\n",
       "[8315 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fra horse tut\r\n",
    "# frames = [X_train, y_train]\r\n",
    "\r\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\r\n",
    "# data_dmatrix = xgb.DMatrix(data=X,label=y) PRØV DETTE\r\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO \r\n",
    "\r\n",
    "From now on, we need to figure out how to train and test a model. We cannot follow any found toturial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "          importance_type='gain', interaction_constraints='',\n",
       "          learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "          min_child_weight=1, missing=0, monotone_constraints='()',\n",
       "          n_estimators=100, n_jobs=4, num_parallel_tree=1, objective='rank:map',\n",
       "          random_state=24, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "          seed=24, subsample=1, tree_method='exact', validate_parameters=1,\n",
       "          verbosity=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dette er fra statquest video, men det virker ikke helt. \r\n",
    "groups = train_data.groupby(train_data.index.values).size().to_frame('size')['size'].to_numpy()\r\n",
    "\r\n",
    "clf_xgb = xgb.XGBRanker(objective=\"rank:map\", missing=0, seed=24)\r\n",
    "clf_xgb.fit(X_train,\r\n",
    "            y_train,\r\n",
    "            verbose=True,\r\n",
    "            # early_stopping_rounds=10,\r\n",
    "            qid=groups,\r\n",
    "            eval_metric='map')\r\n",
    "            # eval_set=[(X_test,y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf_xgb.predict(X_test)\r\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETTE SER UD TIL AT VIRKE; MEN VI SKAL FINDE UD AF HVORDAN VI KAN DISPLAY RESULTATERNE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe useful\r\n",
    "\r\n",
    "# should be in reverse order of relevance score\r\n",
    "# print( y_train[gbm.predict_proba(X)[:, 1].argsort()][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=0.9, eta=0.05, gamma=0, gpu_id=0,\n",
       "          importance_type='gain', interaction_constraints='', learning_rate=0.1,\n",
       "          max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "          monotone_constraints='()', n_estimators=110, n_jobs=4,\n",
       "          num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "          scale_pos_weight=None, subsample=0.75, tree_method='gpu_hist',\n",
       "          validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dette er fra horse tut\r\n",
    "# Groups created \r\n",
    "groups = train_data.groupby(train_data.index.values).size().to_frame('size')['size'].to_numpy()\r\n",
    "\r\n",
    "model = xgb.XGBRanker(  \r\n",
    "    tree_method='gpu_hist',\r\n",
    "    booster='gbtree',\r\n",
    "    objective='rank:pairwise',\r\n",
    "    random_state=42, \r\n",
    "    learning_rate=0.1,\r\n",
    "    colsample_bytree=0.9, \r\n",
    "    eta=0.05, \r\n",
    "    max_depth=6, \r\n",
    "    n_estimators=110, \r\n",
    "    subsample=0.75 \r\n",
    "    )\r\n",
    "\r\n",
    "model.fit(X_train, y_train, group=groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, ..., 0.5, 0.5, 0.5], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train,y_train)\r\n",
    "\r\n",
    "preds = model.predict(X_test)\r\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-fold cross validation\r\n",
    "\r\n",
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\r\n",
    "                'max_depth': 5, 'alpha': 10}\r\n",
    "\r\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\r\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\r\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12397</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12404</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12407</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12408</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12409</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7446 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [1, 3, 6, 7, 10, 12, 14, 16, 17, 18, 19, 22, 25, 26, 29, 31, 32, 33, 34, 35, 41, 43, 44, 45, 48, 49, 50, 55, 57, 58, 59, 61, 64, 68, 71, 72, 73, 74, 76, 77, 78, 84, 86, 87, 88, 90, 92, 93, 103, 104, 105, 106, 107, 110, 111, 113, 114, 115, 118, 119, 120, 122, 124, 126, 127, 128, 129, 132, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 148, 150, 153, 155, 156, 157, 159, 160, 164, 165, 166, 167, 168, 169, 170, 171, 172, 174, 176, 178, 182, ...]\n",
       "\n",
       "[7446 rows x 0 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\r\n",
    "\r\n",
    "\r\n",
    "gss = GroupShuffleSplit(test_size=.40, n_splits=1, random_state = 7).split(X, groups=X_encoded.index.values)\r\n",
    "X_train_inds, X_test_inds = next(gss)\r\n",
    "\r\n",
    "train_data= X_encoded.iloc[X_train_inds]\r\n",
    "X_train = train_data.loc[:, ~train_data.columns.isin(['STRATUM','GENDER_bin','HI_GRADE_AVG'])]\r\n",
    "y_train = train_data.loc[:, train_data.columns.isin(['COL_GRADE_AVG'])]\r\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= X_encoded.iloc[X_test_inds]\r\n",
    "X_test = test_data.loc[:, ~test_data.columns.isin(['STRATUM','GENDER_bin','HI_GRADE_AVG'])]\r\n",
    "y_test = test_data.loc[:, test_data.columns.isin(['COL_GRADE_AVG'])]\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[14:42:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/data/data.cc:563: Check failed: group_ptr_.back() == num_row_ (8315 vs. 7446) : Invalid group structure.  Number of rows obtained from groups doesn't equal to actual number of rows given by data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-57279815c5cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, group, qid, sample_weight, base_margin, eval_set, eval_group, eval_qid, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1596\u001b[0m             )\n\u001b[0;32m   1597\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1599\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [14:42:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/data/data.cc:563: Check failed: group_ptr_.back() == num_row_ (8315 vs. 7446) : Invalid group structure.  Number of rows obtained from groups doesn't equal to actual number of rows given by data."
     ]
    }
   ],
   "source": [
    "\r\n",
    "import xgboost as xgb\r\n",
    "\r\n",
    "model = xgb.XGBRanker(  \r\n",
    "    tree_method='gpu_hist',\r\n",
    "    booster='gbtree',\r\n",
    "    objective='rank:pairwise',\r\n",
    "    random_state=42, \r\n",
    "    learning_rate=0.1,\r\n",
    "    colsample_bytree=0.9, \r\n",
    "    eta=0.05, \r\n",
    "    max_depth=6, \r\n",
    "    n_estimators=110, \r\n",
    "    subsample=0.75 \r\n",
    "    )\r\n",
    "\r\n",
    "model.fit(X_train, y_train, group=groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STRATUM</th>\n",
       "      <th>HI_GRADE_AVG</th>\n",
       "      <th>GENDER_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stratum_4</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stratum_2</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stratum_4</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stratum_6</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stratum_2</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12402</th>\n",
       "      <td>Stratum_2</td>\n",
       "      <td>62.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12403</th>\n",
       "      <td>Stratum_3</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12405</th>\n",
       "      <td>Stratum_2</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12406</th>\n",
       "      <td>Stratum_2</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12410</th>\n",
       "      <td>Stratum_3</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4965 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         STRATUM  HI_GRADE_AVG  GENDER_bin\n",
       "0      Stratum_4     74.666667           1\n",
       "2      Stratum_2     43.000000           0\n",
       "4      Stratum_4     77.666667           0\n",
       "5      Stratum_6     66.333333           1\n",
       "8      Stratum_2     53.666667           0\n",
       "...          ...           ...         ...\n",
       "12402  Stratum_2     62.333333           1\n",
       "12403  Stratum_3     63.000000           1\n",
       "12405  Stratum_2     69.000000           0\n",
       "12406  Stratum_2     73.333333           0\n",
       "12410  Stratum_3     66.666667           0\n",
       "\n",
       "[4965 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, df):\r\n",
    "    return model.predict(df.loc[:, ~df.columns.isin(['STRATUM','GENDER_bin','HI_GRADE_AVG'])])\r\n",
    "    \r\n",
    "# X_train = train_data.loc[:, ~train_data.columns.isin(['STRATUM','GENDER_bin','HI_GRADE_AVG'])]\r\n",
    "\r\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 9, got 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-f7734e680dc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m predictions = (data.groupby('STRATUM')\n\u001b[0m\u001b[0;32m      3\u001b[0m                .apply(lambda x: predict(model, x)))\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.chained_assignment\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m                 \u001b[1;31m# gh-20949\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[1;34m(self, f, data)\u001b[0m\n\u001b[0;32m    926\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m         \"\"\"\n\u001b[1;32m--> 928\u001b[1;33m         \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;31m# group might be modified\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-91-f7734e680dc8>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m predictions = (data.groupby('STRATUM')\n\u001b[1;32m----> 3\u001b[1;33m                .apply(lambda x: predict(model, x)))\n\u001b[0m",
      "\u001b[1;32m<ipython-input-90-b116971d5547>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(model, df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'STRATUM'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'GENDER_bin'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'HI_GRADE_AVG'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# X_train = train_data.loc[:, ~train_data.columns.isin(['STRATUM','GENDER_bin','HI_GRADE_AVG'])]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 820\u001b[1;33m                 predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[0;32m    821\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m                     \u001b[0miteration_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   1839\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1841\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1842\u001b[0m                     \u001b[1;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m                     \u001b[1;34mf\"got {data.shape[0]}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 9, got 7"
     ]
    }
   ],
   "source": [
    "\r\n",
    "data = test_data\r\n",
    "predictions = (data.groupby('STRATUM')\r\n",
    "               .apply(lambda x: predict(model, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/foxtrotmike/xgbrank/blob/master/xgbranker.py\r\n",
    "   \r\n",
    "import xgboost\r\n",
    "from xgboost import XGBModel\r\n",
    "from xgboost import DMatrix, train\r\n",
    "import numpy as np\r\n",
    "class XGBRanker(XGBModel):\r\n",
    "    __doc__ = \"\"\"Implementation of sklearn API for XGBoost Ranking\r\n",
    "           \"\"\" + '\\n'.join(XGBModel.__doc__.split('\\n')[2:])\r\n",
    "    \r\n",
    "    def __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, \r\n",
    "                 silent=True, objective=\"rank:pairwise\", booster='gbtree',\r\n",
    "                 n_jobs=-1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0,\r\n",
    "                 subsample=1, colsample_bytree=1, colsample_bylevel=1,\r\n",
    "                 reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\r\n",
    "                 base_score=0.5, random_state=0, seed=None, missing=None, **kwargs): \r\n",
    "        \r\n",
    "        super(XGBRanker, self).__init__(max_depth, learning_rate,\r\n",
    "                                        n_estimators, silent, objective, booster,\r\n",
    "                                        n_jobs, nthread, gamma, min_child_weight, max_delta_step, \r\n",
    "                                        subsample, colsample_bytree, colsample_bylevel,\r\n",
    "                                        reg_alpha, reg_lambda, scale_pos_weight,\r\n",
    "                                        base_score, random_state, seed, missing)\r\n",
    "\r\n",
    "\r\n",
    "    def fit(self, X, y, group=None, eval_metric=None, sample_weight=None,\r\n",
    "            early_stopping_rounds=None, verbose=True):\r\n",
    "        \"\"\"\r\n",
    "        Fit the gradient boosting model\r\n",
    "        Parameters\r\n",
    "        ----------\r\n",
    "        X : array_like\r\n",
    "            Feature matrix\r\n",
    "        y : array_like\r\n",
    "            Labels\r\n",
    "        group : list, optional\r\n",
    "            Group number list. All X and y will be taken as single group when group is not provided. All ranking is valid only in their own group.\r\n",
    "        sample_weight : array_like\r\n",
    "            instance weights\r\n",
    "        eval_set : list, optional\r\n",
    "            A list of (X, y) tuple pairs to use as a validation set for\r\n",
    "            early-stopping\r\n",
    "        eval_metric : str, callable, optional\r\n",
    "            If a str, should be a built-in evaluation metric to use. See\r\n",
    "            doc/parameter.md. If callable, a custom evaluation metric. The call\r\n",
    "            signature is func(y_predicted, y_true) where y_true will be a\r\n",
    "            DMatrix object such that you may need to call the get_label\r\n",
    "            method. It must return a str, value pair where the str is a name\r\n",
    "            for the evaluation and value is the value of the evaluation\r\n",
    "            function. This objective is always minimized.\r\n",
    "        early_stopping_rounds : int\r\n",
    "            Activates early stopping. Validation error needs to decrease at\r\n",
    "            least every <early_stopping_rounds> round(s) to continue training.\r\n",
    "            Requires at least one item in evals.  If there's more than one,\r\n",
    "            will use the last. Returns the model from the last iteration\r\n",
    "            (not the best one). If early stopping occurs, the model will\r\n",
    "            have three additional fields: bst.best_score, bst.best_iteration\r\n",
    "            and bst.best_ntree_limit.\r\n",
    "            (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\r\n",
    "            and/or num_class appears in the parameters)\r\n",
    "        verbose : bool\r\n",
    "            If `verbose` and an evaluation set is used, writes the evaluation\r\n",
    "            metric measured on the validation set to stderr.\r\n",
    "        xgb_model : str\r\n",
    "            file name of stored xgb model or 'Booster' instance Xgb model to be\r\n",
    "            loaded before training (allows training continuation).\r\n",
    "        \"\"\"\r\n",
    "        if group is None:\r\n",
    "            group = [X.shape[0]]\r\n",
    "        else:\r\n",
    "            idx = np.argsort(group)\r\n",
    "            X = X[idx,:]\r\n",
    "            y = y[idx]\r\n",
    "            group = group[idx]\r\n",
    "            unique, counts = np.unique(group, return_counts=True)\r\n",
    "            group = counts[np.argsort(unique)]\r\n",
    "        \r\n",
    "        params = self.get_xgb_params()\r\n",
    " \r\n",
    "        if callable(self.objective):\r\n",
    "            obj = _objective_decorator(self.objective)\r\n",
    "            # Use default value. Is it really not used ?\r\n",
    "            xgb_options[\"objective\"] = \"rank:pairwise\"\r\n",
    "        else:\r\n",
    "            obj = None\r\n",
    "        \r\n",
    "        evals_result = {}\r\n",
    "        feval = eval_metric if callable(eval_metric) else None\r\n",
    "        if eval_metric is not None:\r\n",
    "            if callable(eval_metric):\r\n",
    "                eval_metric = None\r\n",
    "            else:\r\n",
    "                params.update({'eval_metric': eval_metric})\r\n",
    "\r\n",
    "        if sample_weight is not None:\r\n",
    "            train_dmatrix = DMatrix(X, label=y, weight=sample_weight,\r\n",
    "                                    missing=self.missing)\r\n",
    "        else:\r\n",
    "            train_dmatrix = DMatrix(X, label=y,\r\n",
    "                                    missing=self.missing)\r\n",
    "        train_dmatrix.set_group(group)\r\n",
    "        \r\n",
    "        self.objective = params[\"objective\"]\r\n",
    "\r\n",
    "        self._Booster = train(params, train_dmatrix, \r\n",
    "                              self.n_estimators,\r\n",
    "                              early_stopping_rounds=early_stopping_rounds,\r\n",
    "                              evals_result=evals_result, obj=obj, feval=feval,\r\n",
    "                              verbose_eval=verbose,\r\n",
    "                              xgb_model=None)\r\n",
    "\r\n",
    "        \r\n",
    "        if evals_result:\r\n",
    "            for val in evals_result.items():\r\n",
    "                evals_result_key = list(val[1].keys())[0]\r\n",
    "                evals_result[val[0]][evals_result_key] = val[1][evals_result_key]\r\n",
    "            self.evals_result = evals_result\r\n",
    "\r\n",
    "        if early_stopping_rounds is not None:\r\n",
    "            self.best_score = self._Booster.best_score\r\n",
    "            self.best_iteration = self._Booster.best_iteration\r\n",
    "            self.best_ntree_limit = self._Booster.best_ntree_limit\r\n",
    "\r\n",
    "        return self\r\n",
    "\r\n",
    "    def predict(self, X, group=None, output_margin=False, ntree_limit=0):\r\n",
    "        unsort = (group is not None)\r\n",
    "        if group == None:\r\n",
    "            group = [X.shape[0]]            \r\n",
    "        else:\r\n",
    "            idx = np.argsort(group)\r\n",
    "            X = X[idx,:]\r\n",
    "            group = group[idx]\r\n",
    "            unique, counts = np.unique(group, return_counts=True)\r\n",
    "            group = counts[np.argsort(unique)]\r\n",
    "            \r\n",
    "        test_dmatrix = DMatrix(X, missing=self.missing)\r\n",
    "        test_dmatrix.set_group(group)\r\n",
    "        rank_values = self.get_booster().predict(test_dmatrix,\r\n",
    "                                                 output_margin=output_margin,\r\n",
    "                                                 ntree_limit=ntree_limit)\r\n",
    "        if unsort:\r\n",
    "            rank_values=rank_values[np.argsort(idx)]\r\n",
    "        return rank_values\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-fdc4a0f3b2c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXGBModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "XGBModel.fit(X_train, y_train, eval_metric=None, sample_weight=None,early_stopping_rounds=None, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mq2008.train.group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-b73f4db019cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgroup_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mq2008.train.group\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mq2008.train.group'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\r\n",
    "from xgboost import DMatrix\r\n",
    "\r\n",
    "group_train = []\r\n",
    "with open(X_train, \"r\") as f:\r\n",
    "    data = f.readlines()\r\n",
    "    for line in data:\r\n",
    "        group_train.append(int(line.split(\"\\n\")[0]))\r\n",
    "\r\n",
    "group_valid = []\r\n",
    "with open(\"mq2008.vali.group\", \"r\") as f:\r\n",
    "    data = f.readlines()\r\n",
    "    for line in data:\r\n",
    "        group_valid.append(int(line.split(\"\\n\")[0]))\r\n",
    "\r\n",
    "group_test = []\r\n",
    "with open(\"mq2008.test.group\", \"r\") as f:\r\n",
    "    data = f.readlines()\r\n",
    "    for line in data:\r\n",
    "        group_test.append(int(line.split(\"\\n\")[0]))\r\n",
    "\r\n",
    "train_dmatrix = DMatrix(X_train, y_train)\r\n",
    "valid_dmatrix = DMatrix(X_test, y_test)\r\n",
    "test_dmatrix = DMatrix(x_test)\r\n",
    "\r\n",
    "train_dmatrix.set_group(group_train)\r\n",
    "valid_dmatrix.set_group(group_valid)\r\n",
    "\r\n",
    "params = {'objective': 'rank:ndcg', 'eta': 0.1, 'gamma': 1.0,\r\n",
    "          'min_child_weight': 0.1, 'max_depth': 6}\r\n",
    "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=4,\r\n",
    "                      evals=[(valid_dmatrix, 'validation')])\r\n",
    "pred = xgb_model.predict(test_dmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2b6eb828a06aba2a5f38c98b0f742e720c3c24745e1f8335692b0a3c2eb5e5e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}